{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dadea2b-85c5-47b0-a7f1-1bfa7fa73e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3=1.28.63, botocore=1.31.63\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "print(f\"boto3={boto3.__version__}, botocore={botocore.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  List Foundation Models in Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.Bedrock at 0x10cdd5410>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client = boto3.client(service_name='bedrock',\n",
    "                              region_name='us-east-1')\n",
    "bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '30aec59a-ee25-467a-8e80-9014872fa67b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 02 Jan 2024 14:54:35 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '17477',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '30aec59a-ee25-467a-8e80-9014872fa67b'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large',\n",
       "   'modelName': 'Titan Text Large',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium',\n",
       "   'modelName': 'Titan Text Embeddings',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0',\n",
       "   'modelId': 'amazon.titan-image-generator-v1:0',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1',\n",
       "   'modelId': 'amazon.titan-image-generator-v1',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02',\n",
       "   'modelName': 'Titan Text Embeddings v2',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelId': 'amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1',\n",
       "   'modelId': 'amazon.titan-text-lite-v1',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'modelId': 'amazon.titan-text-express-v1:0:8k',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelId': 'amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "   'modelId': 'amazon.titan-embed-image-v1:0',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1',\n",
       "   'modelId': 'amazon.titan-embed-image-v1',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1:0',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct',\n",
       "   'modelName': 'J2 Grande Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct',\n",
       "   'modelName': 'J2 Jumbo Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k',\n",
       "   'modelId': 'anthropic.claude-instant-v1:2:100k',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k',\n",
       "   'modelId': 'anthropic.claude-v2:0:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k',\n",
       "   'modelId': 'anthropic.claude-v2:0:100k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k',\n",
       "   'modelId': 'anthropic.claude-v2:1:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k',\n",
       "   'modelId': 'anthropic.claude-v2:1:200k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1',\n",
       "   'modelId': 'anthropic.claude-v2:1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-text-v14:7:4k',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-light-text-v14:7:4k',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14',\n",
       "   'modelId': 'cohere.command-light-text-v14',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3',\n",
       "   'modelId': 'cohere.embed-english-v3',\n",
       "   'modelName': 'Embed English',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3',\n",
       "   'modelId': 'cohere.embed-multilingual-v3',\n",
       "   'modelName': 'Embed Multilingual',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': []},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND']},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': []},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1',\n",
       "   'modelId': 'meta.llama2-13b-v1',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': []},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': []},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1',\n",
       "   'modelId': 'meta.llama2-70b-v1',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': []}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Text Generation Models #####\n",
      "amazon.titan-tg1-large\n",
      "amazon.titan-text-lite-v1:0:4k\n",
      "amazon.titan-text-lite-v1\n",
      "amazon.titan-text-express-v1:0:8k\n",
      "amazon.titan-text-express-v1\n",
      "ai21.j2-grande-instruct\n",
      "ai21.j2-jumbo-instruct\n",
      "ai21.j2-mid\n",
      "ai21.j2-mid-v1\n",
      "ai21.j2-ultra\n",
      "ai21.j2-ultra-v1\n",
      "anthropic.claude-instant-v1:2:100k\n",
      "anthropic.claude-instant-v1\n",
      "anthropic.claude-v1\n",
      "anthropic.claude-v2:0:18k\n",
      "anthropic.claude-v2:0:100k\n",
      "anthropic.claude-v2:1:18k\n",
      "anthropic.claude-v2:1:200k\n",
      "anthropic.claude-v2:1\n",
      "anthropic.claude-v2\n",
      "cohere.command-text-v14:7:4k\n",
      "cohere.command-text-v14\n",
      "cohere.command-light-text-v14:7:4k\n",
      "cohere.command-light-text-v14\n",
      "meta.llama2-13b-chat-v1:0:4k\n",
      "meta.llama2-13b-chat-v1\n",
      "meta.llama2-70b-chat-v1:0:4k\n",
      "meta.llama2-70b-chat-v1\n",
      "meta.llama2-13b-v1:0:4k\n",
      "meta.llama2-13b-v1\n",
      "meta.llama2-70b-v1:0:4k\n",
      "meta.llama2-70b-v1\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_client.list_foundation_models()\n",
    "model_list = response['modelSummaries']\n",
    "\n",
    "print(\"##### Text Generation Models #####\")\n",
    "for model in model_list:\n",
    "    if model['outputModalities'] == [\"TEXT\"]:\n",
    "        print(model['modelId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Embedding Models #####\n",
      "amazon.titan-e1t-medium\n",
      "amazon.titan-embed-g1-text-02\n",
      "amazon.titan-embed-text-v1:2:8k\n",
      "amazon.titan-embed-text-v1\n",
      "amazon.titan-embed-image-v1:0\n",
      "amazon.titan-embed-image-v1\n",
      "cohere.embed-english-v3\n",
      "cohere.embed-multilingual-v3\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Embedding Models #####\")\n",
    "for model in model_list:\n",
    "    if model['outputModalities'] == [\"EMBEDDING\"]:\n",
    "        print(model['modelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### IMAGE Models #####\n",
      "amazon.titan-image-generator-v1:0\n",
      "amazon.titan-image-generator-v1\n",
      "stability.stable-diffusion-xl\n",
      "stability.stable-diffusion-xl-v0\n",
      "stability.stable-diffusion-xl-v1:0\n",
      "stability.stable-diffusion-xl-v1\n"
     ]
    }
   ],
   "source": [
    "print(\"##### IMAGE Models #####\")\n",
    "for model in model_list:\n",
    "    if model['outputModalities'] == [\"IMAGE\"]:\n",
    "        print(model['modelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Foundation Models for Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.BedrockRuntime at 0x10d163d50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_runtime_client = boto3.client(service_name='bedrock-runtime',\n",
    "                              region_name='us-east-1')\n",
    "bedrock_runtime_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0f31ef8-60f1-422d-ba99-35b48029d8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "accept = 'application/json' \n",
    "content_type = 'application/json'\n",
    "\n",
    "prompt_data = 'What is Generative AI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Titan Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative AI, also known as machine learning, is a field of computer science that focuses on developing algorithms that can create new content, such as images, text, music, and videos, from scratch. It involves training neural networks to learn patterns and generate new data based on those patterns.\n",
      "\n",
      "There are different types of generative AI, including image generation, text generation, and music generation. Image generation involves training neural networks to create new images based on a given set of instructions, such as drawing a specific object or person. Text generation involves training neural networks to generate new text based on a given prompt or set of data. Music generation involves training neural networks to create new music based on a given set of notes or chords.\n",
      "\n",
      "Generative AI has many applications in various fields, such as art, music, healthcare, and finance. For example, it can be used to create personalized artwork, generate realistic images, and create natural language responses to user queries. It can also be used to generate fake news, detect fraud, and improve financial forecasting.\n",
      "\n",
      "However, there are also concerns about the ethical implications of generative AI, such as the potential for it to be used to create fake news, manipulate public opinion, or automate unfair labor practices. It is important for developers and policymakers to address these concerns and ensure that generative AI is used in a responsible and ethical manner.\n",
      "\n",
      "Overall, generative AI is a rapidly evolving field with the potential to transform many industries and improve our lives. However, it is important to approach it with caution and to ensure that it is used in a responsible and ethical manner.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'amazon.titan-text-express-v1'\n",
    "\n",
    "text_gen_config = {\n",
    "    \"maxTokenCount\": 512,\n",
    "    \"stopSequences\": [], \n",
    "    \"temperature\": 0,\n",
    "    \"topP\": 0.9\n",
    "}\n",
    "\n",
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data,\n",
    "    \"textGenerationConfig\": text_gen_config  \n",
    "})\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                contentType=content_type,\n",
    "                accept = accept,\n",
    "                body=body,\n",
    "            )\n",
    "\n",
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Anthropic Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generative AI refers to artificial intelligence systems that are designed to generate new content such as images, video, audio, text or code by learning patterns and styles from large amounts of existing data.\n",
      "\n",
      "Some key characteristics of generative AI include:\n",
      "\n",
      "- It uses machine learning algorithms like neural networks to be able to learn statistical patterns in data and create new data that fits those patterns. These algorithms allow the models to generalize beyond the training data.\n",
      "\n",
      "- The new generated content looks realistic because the models have learned the inherent structure and patterns contained within natural data like images, audio, text etc. \n",
      "\n",
      "- Popular generative AI techniques include Generative Adversarial Networks (GANs) which pit two neural networks against each other to generate synthetic data, and Variational Autoencoders which learn the probabilistic distribution of data and can generate new examples from the learned distribution.\n",
      "\n",
      "- Applications of generative AI include image generation, art creation, converting styles between images/videos, text summarization, translation between languages, composing music, and more.\n",
      "\n",
      "- As generative models become larger and more powerful with advances in AI, they can be used to generate synthetic media like images, video, audio that can be increasingly difficult to distinguish from human-created content.\n",
      "\n",
      "So in summary, generative AI uses machine learning to learn patterns in data and synthetically generate new data that reflects the same underlying probability distributions as the training dataset. This allows creation of realistic novel\n"
     ]
    }
   ],
   "source": [
    "model_id = 'anthropic.claude-instant-v1'\n",
    "\n",
    "prompt = \"Human: \" + prompt_data + \" \\\\nAssistant:\"\n",
    "\n",
    "body = {\"prompt\": prompt,\n",
    "        \"max_tokens_to_sample\": 300, \n",
    "        \"temperature\": 1,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0.999,\n",
    "        \"stop_sequences\": [\"\\\\n\\\\nHuman:\"],\n",
    "        }\n",
    "\n",
    "body = json.dumps(body)\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                 modelId=model_id, \n",
    "                                 accept=accept, \n",
    "                                 contentType=content_type)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gener\n",
      "ative AI refers to artificial intelligence systems that are able to generate new content such as images, videos, text or audio. Here\n",
      " are some key\n",
      " things to know about generative AI:\n",
      "\n",
      "- The main goal of generative AI is to learn patterns\n",
      " from large datasets in order to generate new samples that are similar to the training data\n",
      ". For example, a generative AI system trained on millions of images should be able to generate new photorealistic images that\n",
      " have never existed before.\n",
      "\n",
      "- Modern generative AI is often based on\n",
      " deep learning techniques like generative adversarial networks (GANs) and transformer models. These use neural networks to learn the underlying\n",
      " probability distributions of the training data\n",
      ". \n",
      "\n",
      "- Popular generative AI applications include image generation, text generation, video generation\n",
      ", audio generation and more. Well-known examples include\n",
      " Deepfakes for faceswapping videos, copywriting\n",
      " AI systems and generative art/design programs.\n",
      "\n",
      "- Some generative\n",
      " AI may raising legal and ethical issues around manipulated media, bias, privacy\n",
      " and over-reliance. Researchers are working on techniques like contextualization\n",
      " to help address such concerns.\n",
      "\n",
      "- The potential for generative AI is huge\n",
      " in areas like artificial content creation, personalized experiences, scientific discovery\n",
      " and more. But developing robust and beneficial systems\n",
      " remains an\n",
      " active challenge for\n",
      " the field.\n",
      "\n",
      "In summary, generative AI aims to\n",
      " automatically produce novel outcomes based on patterns learned from data, with wide\n",
      "-ranging implications and opportunities across many industries.\n"
     ]
    }
   ],
   "source": [
    "#We can also call the Anthropic Claude models via the streaming API\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model_with_response_stream(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                 modelId=model_id, \n",
    "                                 accept=accept, \n",
    "                                 contentType=content_type)\n",
    "\n",
    "for event in response['body']:\n",
    "    data = json.loads(event['chunk']['bytes'])\n",
    "    print(data['completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Meta Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a type of artificial intelligence that can generate new and original content, such as images, videos, music, or text. This is in contrast to other types of AI that focus on recognizing and classifying existing patterns. Generative AI models use complex algorithms to learn patterns within the data they are trained on, and then use this knowledge to create new content that resembles the original data. Some examples of generative AI include deep learning models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as well as more traditional machine learning techniques like decision trees and neural networks. These models can be used in a variety of applications, such as creating realistic virtual environments for video games or simulators, generating personalized content for users, or creating synthetic data for training other AI models.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'meta.llama2-13b-chat-v1'\n",
    "\n",
    "body = json.dumps({ \n",
    "\t'prompt': prompt,\n",
    "    'max_gen_len': 512,\n",
    "\t'top_p': 0.9,\n",
    "\t'temperature': 0.2\n",
    "})\n",
    "\n",
    "#Invoke the model\n",
    "response = bedrock_runtime_client.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                 modelId=model_id, \n",
    "                                 accept=accept, \n",
    "                                 contentType=content_type)\n",
    "\n",
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('generation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Cohere Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generative AI is a type of artificial intelligence that can create new data that is similar to the training data it has been given. Generative AI is a subset of machine learning (ML) techniques and is trained using deep learning (DL) algorithms to generate new data. Generative AI can be used to create new images, videos, audio files, and text data.\n",
      "\n",
      "One of the most common types of generative AI is Generative Adversarial Networks (GANs). GANs consist of two neural networks: a generator and a discriminator. The generator creates new data objects, while the discriminator tries to distinguish the created data from real data. The generator and discriminator are trained together in a competitive game, with the generator getting better at generating more realistic data and the discriminator getting better at telling the difference between real and generated data.\n",
      "\n",
      "Generative AI can be used for many applications, including creating realistic images and videos, generating synthetic data for training other machine learning models, and even creating new music and art. Generative AI can also be used for data augmentation, where it is used to generate new data to augment existing data sets for improved model training.\n",
      "\n",
      "Overall, generative AI is an exciting and rapidly developing field of AI research, with many potential applications in a variety of industries.\n",
      "\n",
      "Would you like to know more about Generative AI? \n"
     ]
    }
   ],
   "source": [
    "model_id = 'cohere.command-text-v14' \n",
    "\n",
    "body = {\n",
    "    \"prompt\": prompt_data,\n",
    "    \"max_tokens\": 400,\n",
    "    \"temperature\": 0.75,\n",
    "    \"p\": 0.01,\n",
    "    \"k\": 0,\n",
    "    \"stop_sequences\": [],\n",
    "    \"return_likelihoods\": \"NONE\"\n",
    "}\n",
    "\n",
    "body = json.dumps(body).encode('utf-8')\n",
    "\n",
    "#Invoke the model\n",
    "response = bedrock_runtime_client.invoke_model(body=body,\n",
    "                                 modelId=model_id, \n",
    "                                 accept=accept, \n",
    "                                 contentType=content_type)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body['generations'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 AI21 Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative AI refers to a class of machine learning algorithms that can generate new content or create patterns from input data. These algorithms are designed to model and generate probability distributions over data, enabling them to produce new samples that are similar to or similar to the training data. Generative models can be used in a variety of fields, including natural language processing, computer vision, and robotics. Some common examples of generative AI include generative adversarial networks (GANs), variational autoencoders (VAEs), and normalizing flows.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'ai21.j2-ultra' \n",
    "\n",
    "body = {\n",
    "  \"prompt\": prompt_data,\n",
    "  \"maxTokens\": 200,\n",
    "  \"temperature\": 0.7,\n",
    "  \"topP\": 1,\n",
    "  \"stopSequences\": [],\n",
    "  \"countPenalty\": {\n",
    "    \"scale\": 0\n",
    "  },\n",
    "  \"presencePenalty\": {\n",
    "    \"scale\": 0    \n",
    "  },\n",
    "  \"frequencyPenalty\": {\n",
    "    \"scale\": 0\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "body = json.dumps(body) # Encode body as JSON string\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "#Invoke the model\n",
    "response = bedrock_runtime_client.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Use Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Titan Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3fdee1b-1142-4145-87da-dec85b2c303f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embedding of length 4096\n",
      "first few values of the embeddings vector -> [0.5390625, -0.051757812, -0.18554688, -0.0546875, 0.43945312, 0.18164062, -0.10449219, -0.25585938, 0.014465332, -0.26367188]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "model_id = 'amazon.titan-e1t-medium'\n",
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "def get_embedding(body: str,\n",
    "                  model_id: str = model_id,\n",
    "                  accept: str = 'application/json',\n",
    "                  content_type: str = 'application/json') -> List:\n",
    "    response = bedrock_runtime_client.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    return embedding\n",
    "\n",
    "body = json.dumps({\"inputText\": \"Hello, what is Generative AI?\"})\n",
    "embedding = get_embedding(body)\n",
    "print(f\"generated embedding of length {len(embedding)}\\nfirst few values of the embeddings vector -> {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Multi Modal Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ba86c-fca8-40e1-987c-33d74f2b65c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Cohere Embed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
